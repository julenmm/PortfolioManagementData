#!/bin/bash

echo "üß™ Testing Airflow Python Environment"
echo "======================================"

# Test 1: Check if containers are running
echo ""
echo "1Ô∏è‚É£  Checking Docker containers..."
if docker-compose ps | grep -q "airflow_scheduler.*Up"; then
    echo "   ‚úÖ Airflow scheduler is running"
else
    echo "   ‚ùå Airflow scheduler is not running"
    echo "   Run: docker-compose up -d"
    exit 1
fi

# Test 2: Check file structure
echo ""
echo "2Ô∏è‚É£  Checking file structure..."
if [ -f "airflow/dags/utils/__init__.py" ]; then
    echo "   ‚úÖ utils/__init__.py exists"
else
    echo "   ‚ùå utils/__init__.py missing"
    echo "   Run: touch airflow/dags/utils/__init__.py"
fi

if [ -f "airflow/dags/utils/api_clients.py" ]; then
    echo "   ‚úÖ utils/api_clients.py exists"
else
    echo "   ‚ùå utils/api_clients.py missing"
fi

if [ -f "airflow/dags/utils/db_helpers.py" ]; then
    echo "   ‚úÖ utils/db_helpers.py exists"
else
    echo "   ‚ùå utils/db_helpers.py missing"
fi

# Test 3: Test imports inside container
echo ""
echo "3Ô∏è‚É£  Testing imports in Airflow container..."
docker-compose exec -T airflow_scheduler python3 << 'PYTHON'
import sys
import os
sys.path.insert(0, '/opt/airflow/dags')
try:
    from utils.api_clients import get_fred_client
    from utils.db_helpers import get_db_hook
    print("   ‚úÖ Imports successful!")
except ImportError as e:
    print(f"   ‚ùå Import failed: {e}")
    sys.exit(1)
PYTHON

if [ $? -eq 0 ]; then
    echo ""
    echo "üéâ All tests passed! Your Airflow is Python-aware!"
    echo ""
    echo "Next steps:"
    echo "  1. Add your API keys to .env"
    echo "  2. Configure Airflow connection: timescaledb_conn"
    echo "  3. Trigger the economic_data_daily_update DAG"
else
    echo ""
    echo "‚ö†Ô∏è  Some tests failed. Check the output above."
    echo ""
    echo "Quick fixes:"
    echo "  docker-compose restart airflow_scheduler"
    echo "  docker-compose exec airflow_scheduler touch /opt/airflow/dags/utils/__init__.py"
fi
